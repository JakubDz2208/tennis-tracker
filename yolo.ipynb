{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\video\\src\\lkpyramid.cpp:1394: error: (-215:Assertion failed) prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size() in function 'cv::`anonymous-namespace'::SparsePyrLKOpticalFlowImpl::calc'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m screen_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     19\u001b[0m     screen_np \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(screen_np, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGRA2RGB)\n\u001b[1;32m---> 21\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreen_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m model_results:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mboxes:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:269\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m conf\n\u001b[0;32m    268\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:246\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:199\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:260\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(preds, im, im0s)\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mon_predict_postprocess_end\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n\u001b[0;32m    263\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(im0s)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\predictor.py:355\u001b[0m, in \u001b[0;36mBasePredictor.run_callbacks\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs all registered callbacks for a specific event.\"\"\"\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mget(event, []):\n\u001b[1;32m--> 355\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\trackers\\track.py:48\u001b[0m, in \u001b[0;36mon_predict_postprocess_end\u001b[1;34m(predictor)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(det) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m tracks \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrackers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tracks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\trackers\\byte_tracker.py:221\u001b[0m, in \u001b[0;36mBYTETracker.update\u001b[1;34m(self, results, img)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_predict(strack_pool)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmc\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m     warp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m     STrack\u001b[38;5;241m.\u001b[39mmulti_gmc(strack_pool, warp)\n\u001b[0;32m    223\u001b[0m     STrack\u001b[38;5;241m.\u001b[39mmulti_gmc(unconfirmed, warp)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\trackers\\utils\\gmc.py:62\u001b[0m, in \u001b[0;36mGMC.apply\u001b[1;34m(self, raw_frame, detections)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplyEcc(raw_frame, detections)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparseOptFlow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplySparseOptFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\trackers\\utils\\gmc.py:250\u001b[0m, in \u001b[0;36mGMC.applySparseOptFlow\u001b[1;34m(self, raw_frame, detections)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m H\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Find correspondences\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m matchedKeypoints, status, err \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcOpticalFlowPyrLK\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprevFrame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprevKeyPoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Leave good correspondences only\u001b[39;00m\n\u001b[0;32m    253\u001b[0m prevPoints \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\video\\src\\lkpyramid.cpp:1394: error: (-215:Assertion failed) prevPyr[level * lvlStep1].size() == nextPyr[level * lvlStep2].size() in function 'cv::`anonymous-namespace'::SparsePyrLKOpticalFlowImpl::calc'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "screen_width = 1920\n",
    "screen_height = 1080\n",
    "\n",
    "capture_width = 1920\n",
    "capture_height = 1080\n",
    "\n",
    "top_left_x = (screen_width - capture_width) // 2\n",
    "top_left_y = (screen_height - capture_height) // 2\n",
    "\n",
    "bounding_box = {'top': top_left_y, 'left': top_left_x, 'width': capture_width, 'height': capture_height}\n",
    "\n",
    "sct = mss()\n",
    "\n",
    "while True:\n",
    "    sct_img = sct.grab(bounding_box)\n",
    "    screen_np = np.array(sct_img)\n",
    "\n",
    "    if screen_np.shape[2] == 4:\n",
    "        screen_np = cv2.cvtColor(screen_np, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "    model_results = model.track(screen_np, persist=True)\n",
    "\n",
    "    for result in model_results:\n",
    "        for box in result.boxes:\n",
    "            xyxys = box.xyxy\n",
    "\n",
    "            for xyxy in xyxys:\n",
    "                cv2.rectangle(screen_np, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow('screen', screen_np)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('bus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 1 skateboard, 68.6ms\n",
      "Speed: 4.0ms preprocess, 68.6ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "res = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "keys: ['boxes', 'masks']\n",
       "masks: ultralytics.engine.results.Masks object\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "orig_img: array([[[122, 148, 172],\n",
       "        [120, 146, 170],\n",
       "        [125, 153, 177],\n",
       "        ...,\n",
       "        [157, 170, 184],\n",
       "        [158, 171, 185],\n",
       "        [158, 171, 185]],\n",
       "\n",
       "       [[127, 153, 177],\n",
       "        [124, 150, 174],\n",
       "        [127, 155, 179],\n",
       "        ...,\n",
       "        [158, 171, 185],\n",
       "        [159, 172, 186],\n",
       "        [159, 172, 186]],\n",
       "\n",
       "       [[128, 154, 178],\n",
       "        [126, 152, 176],\n",
       "        [126, 154, 178],\n",
       "        ...,\n",
       "        [158, 171, 185],\n",
       "        [158, 171, 185],\n",
       "        [158, 171, 185]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[185, 185, 191],\n",
       "        [182, 182, 188],\n",
       "        [179, 179, 185],\n",
       "        ...,\n",
       "        [114, 107, 112],\n",
       "        [115, 105, 111],\n",
       "        [116, 106, 112]],\n",
       "\n",
       "       [[157, 157, 163],\n",
       "        [180, 180, 186],\n",
       "        [185, 186, 190],\n",
       "        ...,\n",
       "        [107,  97, 103],\n",
       "        [102,  92,  98],\n",
       "        [108,  98, 104]],\n",
       "\n",
       "       [[112, 112, 118],\n",
       "        [160, 160, 166],\n",
       "        [169, 170, 174],\n",
       "        ...,\n",
       "        [ 99,  89,  95],\n",
       "        [ 96,  86,  92],\n",
       "        [102,  92,  98]]], dtype=uint8)\n",
       "orig_shape: (1080, 810)\n",
       "path: 'bus.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 4.003047943115234, 'inference': 68.56918334960938, 'postprocess': 8.007049560546875}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[670.1305, 389.6478, 809.4914, 876.5001,   0.8876,   0.0000]], device='cuda:0')\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.8876], device='cuda:0')\n",
      "data: tensor([[670.1305, 389.6478, 809.4914, 876.5001,   0.8876,   0.0000]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[739.8109, 633.0740, 139.3609, 486.8523]], device='cuda:0')\n",
      "xywhn: tensor([[0.9133, 0.5862, 0.1721, 0.4508]], device='cuda:0')\n",
      "xyxy: tensor([[670.1305, 389.6478, 809.4914, 876.5001]], device='cuda:0')\n",
      "xyxyn: tensor([[0.8273, 0.3608, 0.9994, 0.8116]], device='cuda:0')\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[4.9135e+01, 3.9597e+02, 2.4116e+02, 9.0410e+02, 8.5176e-01, 0.0000e+00]], device='cuda:0')\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.8518], device='cuda:0')\n",
      "data: tensor([[4.9135e+01, 3.9597e+02, 2.4116e+02, 9.0410e+02, 8.5176e-01, 0.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[145.1501, 650.0363, 192.0296, 508.1354]], device='cuda:0')\n",
      "xywhn: tensor([[0.1792, 0.6019, 0.2371, 0.4705]], device='cuda:0')\n",
      "xyxy: tensor([[ 49.1353, 395.9686, 241.1649, 904.1040]], device='cuda:0')\n",
      "xyxyn: tensor([[0.0607, 0.3666, 0.2977, 0.8371]], device='cuda:0')\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[2.2319e+02, 4.0759e+02, 3.4404e+02, 8.6208e+02, 8.4200e-01, 0.0000e+00]], device='cuda:0')\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.8420], device='cuda:0')\n",
      "data: tensor([[2.2319e+02, 4.0759e+02, 3.4404e+02, 8.6208e+02, 8.4200e-01, 0.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[283.6157, 634.8316, 120.8563, 454.4893]], device='cuda:0')\n",
      "xywhn: tensor([[0.3501, 0.5878, 0.1492, 0.4208]], device='cuda:0')\n",
      "xyxy: tensor([[223.1875, 407.5870, 344.0438, 862.0762]], device='cuda:0')\n",
      "xyxyn: tensor([[0.2755, 0.3774, 0.4247, 0.7982]], device='cuda:0')\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[  2.4224, 227.8509, 803.0208, 720.6802,   0.8067,   5.0000]], device='cuda:0')\n",
      "cls: tensor([5.], device='cuda:0')\n",
      "conf: tensor([0.8067], device='cuda:0')\n",
      "data: tensor([[  2.4224, 227.8509, 803.0208, 720.6802,   0.8067,   5.0000]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[402.7216, 474.2656, 800.5984, 492.8293]], device='cuda:0')\n",
      "xywhn: tensor([[0.4972, 0.4391, 0.9884, 0.4563]], device='cuda:0')\n",
      "xyxy: tensor([[  2.4224, 227.8509, 803.0208, 720.6802]], device='cuda:0')\n",
      "xyxyn: tensor([[0.0030, 0.2110, 0.9914, 0.6673]], device='cuda:0')\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[0.0000e+00, 5.5113e+02, 7.8033e+01, 8.7385e+02, 3.4271e-01, 0.0000e+00]], device='cuda:0')\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.3427], device='cuda:0')\n",
      "data: tensor([[0.0000e+00, 5.5113e+02, 7.8033e+01, 8.7385e+02, 3.4271e-01, 0.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 39.0165, 712.4895,  78.0330, 322.7209]], device='cuda:0')\n",
      "xywhn: tensor([[0.0482, 0.6597, 0.0963, 0.2988]], device='cuda:0')\n",
      "xyxy: tensor([[  0.0000, 551.1290,  78.0330, 873.8500]], device='cuda:0')\n",
      "xyxyn: tensor([[0.0000, 0.5103, 0.0963, 0.8091]], device='cuda:0')\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[6.6863e+02, 8.2284e+02, 8.1000e+02, 8.8203e+02, 3.3404e-01, 3.6000e+01]], device='cuda:0')\n",
      "cls: tensor([36.], device='cuda:0')\n",
      "conf: tensor([0.3340], device='cuda:0')\n",
      "data: tensor([[6.6863e+02, 8.2284e+02, 8.1000e+02, 8.8203e+02, 3.3404e-01, 3.6000e+01]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[739.3165, 852.4351, 141.3671,  59.1924]], device='cuda:0')\n",
      "xywhn: tensor([[0.9127, 0.7893, 0.1745, 0.0548]], device='cuda:0')\n",
      "xyxy: tensor([[668.6329, 822.8389, 810.0000, 882.0312]], device='cuda:0')\n",
      "xyxyn: tensor([[0.8255, 0.7619, 1.0000, 0.8167]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    for j in i.boxes:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 1 backpack, 53.6ms\n",
      "Speed: 3.0ms preprocess, 53.6ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Boxes' object has no attribute 'get_field'. See valid attributes below.\n\n    A class for storing and manipulating detection boxes.\n\n    Args:\n        boxes (torch.Tensor | numpy.ndarray): A tensor or numpy array containing the detection boxes,\n            with shape (num_boxes, 6) or (num_boxes, 7). The last two columns contain confidence and class values.\n            If present, the third last column contains track IDs.\n        orig_shape (tuple): Original image size, in the format (height, width).\n\n    Attributes:\n        xyxy (torch.Tensor | numpy.ndarray): The boxes in xyxy format.\n        conf (torch.Tensor | numpy.ndarray): The confidence values of the boxes.\n        cls (torch.Tensor | numpy.ndarray): The class values of the boxes.\n        id (torch.Tensor | numpy.ndarray): The track IDs of the boxes (if available).\n        xywh (torch.Tensor | numpy.ndarray): The boxes in xywh format.\n        xyxyn (torch.Tensor | numpy.ndarray): The boxes in xyxy format normalized by original image size.\n        xywhn (torch.Tensor | numpy.ndarray): The boxes in xywh format normalized by original image size.\n        data (torch.Tensor): The raw bboxes tensor (alias for `boxes`).\n\n    Methods:\n        cpu(): Move the object to CPU memory.\n        numpy(): Convert the object to a numpy array.\n        cuda(): Move the object to CUDA memory.\n        to(*args, **kwargs): Move the object to the specified device.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m conf \u001b[38;5;241m=\u001b[39m box\u001b[38;5;241m.\u001b[39mconf\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xyxy \u001b[38;5;129;01min\u001b[39;00m xyxys:\n\u001b[1;32m---> 29\u001b[0m     class_id \u001b[38;5;241m=\u001b[39m \u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnames[class_id]\n\u001b[0;32m     31\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (\u001b[38;5;28mint\u001b[39m(xyxy[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(xyxy[\u001b[38;5;241m1\u001b[39m])), (\u001b[38;5;28mint\u001b[39m(xyxy[\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;28mint\u001b[39m(xyxy[\u001b[38;5;241m3\u001b[39m])), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\utils\\__init__.py:136\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Boxes' object has no attribute 'get_field'. See valid attributes below.\n\n    A class for storing and manipulating detection boxes.\n\n    Args:\n        boxes (torch.Tensor | numpy.ndarray): A tensor or numpy array containing the detection boxes,\n            with shape (num_boxes, 6) or (num_boxes, 7). The last two columns contain confidence and class values.\n            If present, the third last column contains track IDs.\n        orig_shape (tuple): Original image size, in the format (height, width).\n\n    Attributes:\n        xyxy (torch.Tensor | numpy.ndarray): The boxes in xyxy format.\n        conf (torch.Tensor | numpy.ndarray): The confidence values of the boxes.\n        cls (torch.Tensor | numpy.ndarray): The class values of the boxes.\n        id (torch.Tensor | numpy.ndarray): The track IDs of the boxes (if available).\n        xywh (torch.Tensor | numpy.ndarray): The boxes in xywh format.\n        xyxyn (torch.Tensor | numpy.ndarray): The boxes in xyxy format normalized by original image size.\n        xywhn (torch.Tensor | numpy.ndarray): The boxes in xywh format normalized by original image size.\n        data (torch.Tensor): The raw bboxes tensor (alias for `boxes`).\n\n    Methods:\n        cpu(): Move the object to CPU memory.\n        numpy(): Convert the object to a numpy array.\n        cuda(): Move the object to CUDA memory.\n        to(*args, **kwargs): Move the object to the specified device.\n    "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "file_name = \"tenis.mp4\"\n",
    "window_name = \"window\"\n",
    "interframe_wait_ms = 3\n",
    "\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "screen_width = 800  \n",
    "screen_height = 600 \n",
    "\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.resizeWindow(window_name, screen_width, screen_height)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Reached end of video, exiting.\")\n",
    "        break\n",
    "\n",
    "    model_results = model(frame)\n",
    "\n",
    "    for result in model_results:\n",
    "        for box in result.boxes:\n",
    "            xyxys = box.xyxy\n",
    "            conf = box.conf\n",
    "            for xyxy in xyxys:\n",
    "                class_id = box.get_field(\"labels\")\n",
    "                class_name = model.names[class_id]\n",
    "                cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(window_name, frame)\n",
    "    if cv2.waitKey(interframe_wait_ms) & 0x7F == ord('q'):\n",
    "        print(\"Exit requested.\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m first_res \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "first_res = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "keys: ['boxes']\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "orig_img: array([[[ 10,   6,  16],\n",
       "        [ 10,   6,  16],\n",
       "        [  5,   1,  11],\n",
       "        ...,\n",
       "        [  0,   0,   9],\n",
       "        [  0,   0,   9],\n",
       "        [  0,   0,   9]],\n",
       "\n",
       "       [[ 51,  47,  57],\n",
       "        [ 51,  47,  57],\n",
       "        [ 48,  44,  54],\n",
       "        ...,\n",
       "        [ 21,  33,  43],\n",
       "        [ 21,  33,  43],\n",
       "        [ 21,  33,  43]],\n",
       "\n",
       "       [[ 81,  77,  87],\n",
       "        [ 81,  77,  87],\n",
       "        [ 83,  79,  89],\n",
       "        ...,\n",
       "        [ 61,  73,  83],\n",
       "        [ 61,  73,  83],\n",
       "        [ 63,  75,  85]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[238, 239, 244],\n",
       "        [238, 239, 244],\n",
       "        [238, 239, 244],\n",
       "        ...,\n",
       "        [157, 107,  72],\n",
       "        [157, 107,  72],\n",
       "        [157, 107,  72]],\n",
       "\n",
       "       [[238, 239, 244],\n",
       "        [238, 239, 244],\n",
       "        [238, 239, 244],\n",
       "        ...,\n",
       "        [157, 107,  72],\n",
       "        [157, 107,  72],\n",
       "        [157, 107,  72]],\n",
       "\n",
       "       [[238, 239, 244],\n",
       "        [238, 239, 244],\n",
       "        [238, 239, 244],\n",
       "        ...,\n",
       "        [157, 107,  72],\n",
       "        [157, 107,  72],\n",
       "        [157, 107,  72]]], dtype=uint8)\n",
       "orig_shape: (720, 1280)\n",
       "path: 'image0.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': None, 'inference': None, 'postprocess': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_res[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
